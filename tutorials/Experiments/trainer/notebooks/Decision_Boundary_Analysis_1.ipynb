{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ce98e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17169d36",
   "metadata": {},
   "source": [
    "# MLP Decision Boundary Analysis\n",
    "\n",
    "| Method                      | What it gives you                    | Limitation                      |\n",
    "|-----------------------------|--------------------------------------|---------------------------------|\n",
    "| Grid-based visualization    | Decision boundary in 2D/3D          | Not for high dimensions          |\n",
    "| Local linear analysis (per activation) | Local boundary, as affine function | Doesn't scale, local only       |\n",
    "| Polytope enumeration        | Exact regions and boundaries        | Exponential in neurons          |\n",
    "| Boundary sampling/perturbation | Approximate boundary near examples | Not full boundary, local only   |\n",
    "| Attribution (e.g., LIME, saliency) | Boundary proximity per example     | Interpretability, not geometry |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d04ebcf",
   "metadata": {},
   "source": [
    "Applicability on KANs\n",
    "\n",
    "## Applicability of Decision Boundary Methods\n",
    "\n",
    "*   **Grid-based Visualization**\n",
    "    *   **Applicability:** YES for low dimensional input.\n",
    "    *   **Reason:** Regardless of activation type, you can sample a grid of input points, evaluate network output, and plot the decision boundary.\n",
    "    *   **Limitation:** Only practical in 2D/3D and doesn't give full geometric understanding.\n",
    "\n",
    "*   **Local Linear/Affine Analysis**\n",
    "    *   **Applicability:** Possible Locally via Taylor Expansion.\n",
    "    *   **Reason:** For ReLU MLPs, local analysis in each region is exactly linear; for KANs, you can linearize locally via first derivatives (Jacobian).\n",
    "    *   **Consequence:** The boundary is locally approximated by its tangent hyperplane, but it is not globally polyhedral.\n",
    "\n",
    "*   **Boundary Sampling / Perturbation**\n",
    "    *   **Applicability:** Yes.\n",
    "    *   **How:** Move an input example along a vector until the class changes; the crossing point is on the boundary (regardless of activation type).\n",
    "\n",
    "*   **Attribution / Saliency Methods**\n",
    "    *   **Applicability:** Yes.\n",
    "    *   **Why:** Gradient-based and perturbation-based feature attribution works for any differentiable network (including KANs).\n",
    "\n",
    "*   **Polytope Enumeration, Linear Region Counting**\n",
    "    *   **Applicability:** NO, not directly.\n",
    "    *   **Why:** Polytope enumeration works for piecewise linear nets (like ReLU MLPs), because their boundaries are unions of polyhedra. KANs with general nonlinear activations do not produce polyhedral regions. Their decision boundaries are typically smooth (if activations are smooth).\n",
    "\n",
    "*   **Distance to Boundary (Adversarial Example)**\n",
    "    *   **Applicability:** Yes.\n",
    "    *   **Reason:** This is just optimization—find a small perturbation that changes the class. Applicable to any network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20fcaf3",
   "metadata": {},
   "source": [
    "| Method                      | ReLU MLP | KAN       | Comments                             |\n",
    "|-----------------------------|----------|-----------|--------------------------------------|\n",
    "| Grid-based visualization    | Yes      | Yes       | Only in low dimensions                |\n",
    "| Local linear analysis       | Yes      | Approximate | Linear in ReLU, only approximate in KAN |\n",
    "| Boundary sampling/perturbation | Yes      | Yes       | Applicable                           |\n",
    "| Attribution/saliency       | Yes      | Yes       | Applicable                           |\n",
    "| Polytope enumeration        | Yes      | No        | Intractable for KAN with nonlinear units |\n",
    "| Distance to boundary        | Yes      | Yes       | Applicable                           |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b0af03",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0cd6a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fc6151e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D toy data (make_moons)\n",
    "X, y = make_moons(n_samples=1000, noise=0.2, random_state=42)\n",
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.int32)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baa51bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLUMLP(nn.Module):\n",
    "    def __init__(self, n_hidden=16):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8f92e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Spline1D(nn.Module):\n",
    "    def __init__(self, n_knots=10, xmin=-2.0, xmax=3.0):\n",
    "        super().__init__()\n",
    "        self.n_knots = n_knots\n",
    "        self.xmin = xmin\n",
    "        self.xmax = xmax\n",
    "        self.knots = nn.Parameter(torch.linspace(xmin, xmax, n_knots))\n",
    "        self.values = nn.Parameter(torch.rand(n_knots))  # initial function values\n",
    "\n",
    "    def forward(self, x):\n",
    "        # simple linear interpolation; replace with torchinterp or cubic if desired\n",
    "        x = torch.clamp(x, self.xmin, self.xmax)\n",
    "        idx = ((x - self.xmin) / (self.xmax - self.xmin) * (self.n_knots - 1)).long()\n",
    "        idx0 = torch.clamp(idx, 0, self.n_knots - 2)\n",
    "        idx1 = idx0 + 1\n",
    "        x0 = self.knots[idx0]\n",
    "        x1 = self.knots[idx1]\n",
    "        y0 = self.values[idx0]\n",
    "        y1 = self.values[idx1]\n",
    "        t = (x - x0) / (x1 - x0 + 1e-8)\n",
    "        return y0 + t * (y1 - y0)\n",
    "\n",
    "class SimpleKAN(nn.Module):\n",
    "    def __init__(self, n_hidden=16, n_knots=16):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(2, n_hidden)\n",
    "        self.acts1 = nn.ModuleList([Spline1D(n_knots) for _ in range(n_hidden)])\n",
    "        self.lin2 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.acts2 = nn.ModuleList([Spline1D(n_knots) for _ in range(n_hidden)])\n",
    "        self.lin3 = nn.Linear(n_hidden, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = torch.stack([act(x[:,i]) for i, act in enumerate(self.acts1)], dim=1)\n",
    "        x = self.lin2(x)\n",
    "        x = torch.stack([act(x[:,i]) for i, act in enumerate(self.acts2)], dim=1)\n",
    "        x = self.lin3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f728df79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X_train, y_train, epochs=100, lr=1e-2):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    losser = nn.BCEWithLogitsLoss()\n",
    "    X_tensor = torch.tensor(X_train)\n",
    "    y_tensor = torch.tensor(y_train).float().unsqueeze(1)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(X_tensor)\n",
    "        loss = losser(out, y_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch+1) % 20 == 0:\n",
    "            print(f\"Epoch {epoch+1}, loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e08c66",
   "metadata": {},
   "source": [
    "# Decision Boundary Visualization (Grid-based, 2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77581256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(model, X, y, title=\"Decision Boundary\"):\n",
    "    model.eval()\n",
    "    # grid\n",
    "    x_min, x_max = X[:,0].min()-0.5, X[:,0].max()+0.5\n",
    "    y_min, y_max = X[:,1].min()-0.5, X[:,1].max()+0.5\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 300),\n",
    "                         np.linspace(y_min, y_max, 300))\n",
    "    grid = torch.tensor(np.c_[xx.ravel(), yy.ravel()]).float()\n",
    "    with torch.no_grad():\n",
    "        logits = model(grid).cpu().numpy().reshape(xx.shape)\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.contourf(xx, yy, (logits>0).astype(float), alpha=0.4, levels=[0,0.5,1], cmap='RdBu')\n",
    "    plt.scatter(X[:,0], X[:,1], c=y, cmap='RdBu', s=12, edgecolor='k')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b34937",
   "metadata": {},
   "source": [
    "# Boundary Sampling (1D line, \"find where class changes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff621345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundary_sampling(model, fixed_x=0.0, direction='y', num=200):\n",
    "    points = []\n",
    "    coord_vals = np.linspace(-2, 3, num)\n",
    "    for x1 in coord_vals:\n",
    "        pt = [fixed_x, x1] if direction=='y' else [x1, fixed_x]\n",
    "        with torch.no_grad():\n",
    "            p = torch.tensor(pt).float().unsqueeze(0)\n",
    "            logit = model(p).squeeze().item()\n",
    "        label = 1 if logit >= 0 else 0\n",
    "        points.append((pt, label))\n",
    "    # Find where label flips\n",
    "    flips = []\n",
    "    for i in range(1, len(points)):\n",
    "        if points[i][1] != points[i-1][1]:\n",
    "            flips.append(((points[i-1][0], points[i][0])))\n",
    "    print(f\"Boundary crossings along {direction} at fixed {fixed_x}:\")\n",
    "    for a, b in flips:\n",
    "        print(f\"Between {a} and {b}\")\n",
    "    return flips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b32c82",
   "metadata": {},
   "source": [
    "# Attribution/Saliency (Gradient-based w.r.t. input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6873ddaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saliency_map(model, X_sample):\n",
    "    model.eval()\n",
    "    X_var = torch.tensor(X_sample).float().unsqueeze(0).requires_grad_(True)\n",
    "    out = model(X_var)\n",
    "    out.backward()\n",
    "    sal = X_var.grad.detach().numpy()[0]\n",
    "    print(\"Saliency (input gradient):\", sal)\n",
    "    return sal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75fab7c",
   "metadata": {},
   "source": [
    "# Distance to Boundary (FGSM Adversarial Attack, Norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e79d2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_to_boundary(model, X_sample, y_sample, eps=1e-3):\n",
    "    # Binary classification, one-step FGSM\n",
    "    X_var = torch.tensor(X_sample).float().unsqueeze(0).requires_grad_(True)\n",
    "    y_var = torch.tensor([[y_sample]]).float()\n",
    "    model.eval()\n",
    "    out = model(X_var)\n",
    "    loss = F.binary_cross_entropy_with_logits(out, y_var)\n",
    "    loss.backward()\n",
    "    grad = X_var.grad.detach().numpy()[0]\n",
    "    delta = eps * np.sign(grad)\n",
    "    perturbed = X_sample + delta\n",
    "    pred_orig = (torch.sigmoid(out).item() >= 0.5)\n",
    "    out_pert = model(torch.tensor(perturbed).float().unsqueeze(0))\n",
    "    pred_new = (torch.sigmoid(out_pert).item() >= 0.5)\n",
    "    print(f\"Origin pred: {pred_orig}, new pred: {pred_new}\")\n",
    "    print(f\"Perturbation (l2): {np.linalg.norm(delta):.5f}\")\n",
    "    return perturbed, pred_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b326018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, loss: 0.2640\n",
      "Epoch 40, loss: 0.1557\n",
      "Epoch 60, loss: 0.0887\n",
      "Epoch 80, loss: 0.0693\n",
      "Epoch 100, loss: 0.0625\n",
      "Epoch 120, loss: 0.0603\n",
      "Epoch 140, loss: 0.0593\n",
      "Epoch 160, loss: 0.0588\n",
      "Epoch 180, loss: 0.0585\n",
      "Epoch 200, loss: 0.0582\n",
      "Epoch 20, loss: 0.1505\n",
      "Epoch 40, loss: 3.0365\n",
      "Epoch 60, loss: 0.2674\n",
      "Epoch 80, loss: 0.3042\n",
      "Epoch 100, loss: 0.1599\n",
      "Epoch 120, loss: 0.1134\n",
      "Epoch 140, loss: 0.0808\n",
      "Epoch 160, loss: 0.2772\n",
      "Epoch 180, loss: 0.0882\n",
      "Epoch 200, loss: 1.1297\n"
     ]
    }
   ],
   "source": [
    "# Train ReLU MLP\n",
    "relu_mlp = ReLUMLP(n_hidden=32)\n",
    "train(relu_mlp, X_train, y_train, epochs=200)\n",
    "\n",
    "# Train KAN\n",
    "kan = SimpleKAN(n_hidden=32, n_knots=16)\n",
    "train(kan, X_train, y_train, epochs=200)\n",
    "\n",
    "# # Plot decision boundaries\n",
    "# plot_decision_boundary(relu_mlp, X, y, title=\"ReLU MLP Decision Boundary\")\n",
    "# plot_decision_boundary(kan, X, y, title=\"KAN Decision Boundary\")\n",
    "\n",
    "# # Boundary sampling example (vertical line x=0)\n",
    "# boundary_sampling(relu_mlp, fixed_x=0.0, direction='y')\n",
    "# boundary_sampling(kan, fixed_x=0.0, direction='y')\n",
    "\n",
    "# # Saliency example\n",
    "# sample_idx = 0\n",
    "# sal_map = saliency_map(relu_mlp, X[sample_idx])\n",
    "# sal_map_kan = saliency_map(kan, X[sample_idx])\n",
    "\n",
    "# Distance to boundary (adversarial perturbation)\n",
    "# distance_to_boundary(relu_mlp, X[sample_idx], y[sample_idx])\n",
    "# distance_to_boundary(kan, X[sample_idx], y[sample_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dfb175",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12484/3159951768.py:16: FutureWarning: In the future `np.long` will be defined as the corresponding NumPy scalar.\n",
      "  y = y.astype(np.long)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'long'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m X, y \u001b[38;5;241m=\u001b[39m make_moons(n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, noise\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     15\u001b[0m X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m---> 16\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mastype(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m)\n\u001b[1;32m     17\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#------- MODELS -------\u001b[39;00m\n",
      "File \u001b[0;32m/net/store/cv/users/luniehaus/dev-uos/miniconda/envs/pykan/lib/python3.9/site-packages/numpy/__init__.py:320\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tester\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Tester\n\u001b[0;32m--> 320\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'long'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "#------- DATA -------\n",
    "X, y = make_moons(n_samples=1000, noise=0.2, random_state=42)\n",
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.int32)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#------- MODELS -------\n",
    "class ReLUMLP(nn.Module):\n",
    "    def __init__(self, n_hidden=32):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Spline1D(nn.Module):\n",
    "    def __init__(self, n_knots=10, xmin=-2.0, xmax=3.0):\n",
    "        super().__init__()\n",
    "        self.n_knots = n_knots\n",
    "        self.xmin = xmin\n",
    "        self.xmax = xmax\n",
    "        self.knots = nn.Parameter(torch.linspace(xmin, xmax, n_knots), requires_grad=False)\n",
    "        self.values = nn.Parameter(torch.rand(n_knots))  # initial function values\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.clamp(x, self.xmin, self.xmax)\n",
    "        idx_f = (x - self.xmin) / (self.xmax - self.xmin) * (self.n_knots - 1)\n",
    "        idx0 = torch.floor(idx_f).long()\n",
    "        idx1 = torch.clamp(idx0 + 1, max=self.n_knots - 1)\n",
    "        idx0 = torch.clamp(idx0, max=self.n_knots - 2)\n",
    "        x0 = self.knots[idx0]\n",
    "        x1 = self.knots[idx1]\n",
    "        y0 = self.values[idx0]\n",
    "        y1 = self.values[idx1]\n",
    "        t = (x - x0) / (x1 - x0 + 1e-8)\n",
    "        return y0 + t * (y1 - y0)\n",
    "\n",
    "class SimpleKAN(nn.Module):\n",
    "    def __init__(self, n_hidden=32, n_knots=16):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(2, n_hidden)\n",
    "        self.acts1 = nn.ModuleList([Spline1D(n_knots) for _ in range(n_hidden)])\n",
    "        self.lin2 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.acts2 = nn.ModuleList([Spline1D(n_knots) for _ in range(n_hidden)])\n",
    "        self.lin3 = nn.Linear(n_hidden, 1)\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = torch.stack([act(x[:,i]) for i, act in enumerate(self.acts1)], dim=1)\n",
    "        x = self.lin2(x)\n",
    "        x = torch.stack([act(x[:,i]) for i, act in enumerate(self.acts2)], dim=1)\n",
    "        x = self.lin3(x)\n",
    "        return x\n",
    "\n",
    "#------- TRAIN -------\n",
    "def train(model, X_train, y_train, epochs=150, lr=1e-2, verbose=False):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    losser = nn.BCEWithLogitsLoss()\n",
    "    X_tensor = torch.tensor(X_train)\n",
    "    y_tensor = torch.tensor(y_train).float().unsqueeze(1)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(X_tensor)\n",
    "        loss = losser(out, y_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if verbose and (epoch+1) % 50 == 0:\n",
    "            print(f\"Epoch {epoch+1}, loss: {loss.item():.4f}\")\n",
    "\n",
    "# MLP\n",
    "mlp = ReLUMLP(n_hidden=32)\n",
    "train(mlp, X_train, y_train, epochs=200)\n",
    "\n",
    "# KAN\n",
    "kan = SimpleKAN(n_hidden=32, n_knots=16)\n",
    "train(kan, X_train, y_train, epochs=200)\n",
    "\n",
    "#------- UTILITIES -------\n",
    "def plot_decision_boundary(model, X, y, title=\"Decision Boundary\"):\n",
    "    model.eval()\n",
    "    x_min, x_max = X[:,0].min()-0.5, X[:,0].max()+0.5\n",
    "    y_min, y_max = X[:,1].min()-0.5, X[:,1].max()+0.5\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 400),\n",
    "                         np.linspace(y_min, y_max, 400))\n",
    "    grid = torch.tensor(np.c_[xx.ravel(), yy.ravel()]).float()\n",
    "    with torch.no_grad():\n",
    "        logits = model(grid).cpu().numpy().reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, (logits>0).astype(float), alpha=0.35, levels=[0,0.5,1], cmap='RdBu')\n",
    "    plt.scatter(X[:,0], X[:,1], c=y, cmap='RdBu', s=12, edgecolor='k', alpha=0.8)\n",
    "    plt.title(title)\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "\n",
    "def plot_boundary_sampling(model, X, y, fixed_x=0.0, direction='y', num=200, modelname=\"Model\"):\n",
    "    points = []\n",
    "    coord_vals = np.linspace(-2, 3, num)\n",
    "    for x1 in coord_vals:\n",
    "        pt = [fixed_x, x1] if direction=='y' else [x1, fixed_x]\n",
    "        with torch.no_grad():\n",
    "            p = torch.tensor(pt).float().unsqueeze(0)\n",
    "            logit = model(p).squeeze().item()\n",
    "        label = 1 if logit >= 0 else 0\n",
    "        points.append((pt, label))\n",
    "    pts = np.array([pt for pt, _ in points])\n",
    "    labels = np.array([lbl for _, lbl in points])\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plot_decision_boundary(model, X, y, title=f\"{modelname}: Boundary Sampling (fixed {direction}={fixed_x})\")\n",
    "    if direction=='x':\n",
    "        plt.plot(coord_vals, np.full_like(coord_vals, fixed_x), 'k--', lw=1)\n",
    "    else:\n",
    "        plt.plot(np.full_like(coord_vals, fixed_x), coord_vals, 'k--', lw=1)\n",
    "    idxs = np.where(np.abs(np.diff(labels))>0)[0]\n",
    "    for idx in idxs:\n",
    "        a, b = pts[idx], pts[idx+1]\n",
    "        plt.plot([a[0], b[0]], [a[1], b[1]], 'go-', markersize=10, label='Boundary Crossing' if idx==idxs[0] else \"\")\n",
    "    if len(idxs) > 0:\n",
    "        plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_saliency_map(model, X, y, X_sample, y_sample, modelname=\"Model\"):\n",
    "    model.eval()\n",
    "    X_var = torch.tensor(X_sample).float().unsqueeze(0)\n",
    "    X_var.requires_grad = True\n",
    "    out = model(X_var)\n",
    "    out.backward()\n",
    "    sal = X_var.grad.detach().numpy()[0]\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plot_decision_boundary(model, X, y, title=f\"{modelname}: Saliency vector at test pt\")\n",
    "    plt.scatter([X_sample[0]], [X_sample[1]], c=['yellow'], s=80, edgecolor='black', zorder=5, label=\"Input\")\n",
    "    plt.arrow(X_sample[0], X_sample[1], 0.2*sal[0], 0.2*sal[1], color='k', width=0.007)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print(f\"{modelname} saliency (input gradient) =\", np.round(sal,4))\n",
    "\n",
    "def plot_distance_to_boundary(model, X, y, X_sample, y_sample, modelname=\"Model\", eps=0.2):\n",
    "    X_var = torch.tensor(X_sample).float().unsqueeze(0).requires_grad_(True)\n",
    "    y_var = torch.tensor([[y_sample]]).float()\n",
    "    model.eval()\n",
    "    out = model(X_var)\n",
    "    loss = F.binary_cross_entropy_with_logits(out, y_var)\n",
    "    loss.backward()\n",
    "    grad = X_var.grad.detach().numpy()[0]\n",
    "    delta = eps * np.sign(grad)\n",
    "    perturbed = X_sample + delta\n",
    "    pred_orig = (torch.sigmoid(out).item() >= 0.5)\n",
    "    out_pert = model(torch.tensor(perturbed).float().unsqueeze(0))\n",
    "    pred_new = (torch.sigmoid(out_pert).item() >= 0.5)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plot_decision_boundary(model, X, y, title=f\"{modelname}: Adversarial perturbation (eps={eps})\")\n",
    "    plt.scatter([X_sample[0]], [X_sample[1]], c=['yellow'], s=80, label=\"Original\", edgecolor='black', zorder=5)\n",
    "    plt.scatter([perturbed[0]], [perturbed[1]], c=['red'], s=80, label=\"Perturbed\", edgecolor='black', zorder=5)\n",
    "    plt.arrow(X_sample[0], X_sample[1], perturbed[0]-X_sample[0], perturbed[1]-X_sample[1], color='black', width=0.01)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print(f\"{modelname}: original pred={int(pred_orig)}, new pred={int(pred_new)}, L2 perturb={np.linalg.norm(delta):.3f}\")\n",
    "\n",
    "#------- PLOTS -------\n",
    "sample_idx = 0\n",
    "X_sample = X[sample_idx]\n",
    "y_sample = y[sample_idx]\n",
    "\n",
    "#--- MLP\n",
    "plt.figure(figsize=(7,5))\n",
    "plot_decision_boundary(mlp, X, y, title=\"ReLU MLP: Decision Boundary\")\n",
    "plt.show()\n",
    "\n",
    "plot_boundary_sampling(mlp, X, y, fixed_x=0.0, direction='y', modelname=\"ReLU MLP\")\n",
    "\n",
    "plot_saliency_map(mlp, X, y, X_sample, y_sample, modelname=\"ReLU MLP\")\n",
    "\n",
    "plot_distance_to_boundary(mlp, X, y, X_sample, y_sample, modelname=\"ReLU MLP\", eps=0.2)\n",
    "\n",
    "#--- KAN\n",
    "plt.figure(figsize=(7,5))\n",
    "plot_decision_boundary(kan, X, y, title=\"KAN: Decision Boundary\")\n",
    "plt.show()\n",
    "\n",
    "plot_boundary_sampling(kan, X, y, fixed_x=0.0, direction='y', modelname=\"KAN\")\n",
    "\n",
    "plot_saliency_map(kan, X, y, X_sample, y_sample, modelname=\"KAN\")\n",
    "\n",
    "plot_distance_to_boundary(kan, X, y, X_sample, y_sample, modelname=\"KAN\", eps=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3ffa6f",
   "metadata": {},
   "source": [
    "## Ways to Quantify Expressiveness from the Decision Boundary\n",
    "\n",
    "1.  **Counting Linear (or Affine) Regions**\n",
    "    *   **What:** For piecewise (affine) models like ReLU networks, the number of distinct linear regions the decision function splits space into.\n",
    "    *   **Why:** More regions → more \"breaks\"/\"bends\" in the boundary → greater expressiveness.\n",
    "    *   **How:**\n",
    "        *   Exact counting is computationally hard for large nets, but tractable in low dimension or for small nets.\n",
    "        *   Reference: Montúfar et al., 2014; Serra et al., 2018.\n",
    "        *   There are open-source tools that can do this for small networks.\n",
    "    *   **Use:** Compare two networks—the one with more regions is (all else equal) more expressive.\n",
    "\n",
    "2.  **Decision Boundary Length (2D) or Surface Area (Higher d)**\n",
    "    *   **What:** Compute the length of the boundary curve (in 2D) or surface area (in 3D+) separating classes.\n",
    "    *   **Why:** More expressive models can create longer (more convoluted) boundaries.\n",
    "    *   **How (practically in 2D):**\n",
    "        *   Sample a fine grid.\n",
    "        *   Extract the boundary as a set of points (e.g., by looking where the predicted class changes).\n",
    "        *   Estimate total curve length by summing segment distances along the curve.\n",
    "        *   See also Decision Boundary Complexity from Cavalcanti et al., 2018.\n",
    "    *   **Use:** Compare models numerically—the longer the boundary, the more intricate.\n",
    "\n",
    "3.  **Curvature Measures**\n",
    "    *   **What:** How \"bendy\" is the boundary? High total (integrated) curvature = more turns and complexity.\n",
    "    *   **How:**\n",
    "        *   On a grid, approximate the boundary as a collection of points/segments and estimate local curvature.\n",
    "        *   Integrate (sum) the curvature along the boundary.\n",
    "    *   **Use:** Especially relevant for networks with smooth nonlinearities, e.g., KAN, tanh, etc.\n",
    "\n",
    "4.  **Fractal Dimension of the Boundary (for highly expressive models)**\n",
    "    *   **What:** For very irregular boundaries, the fractal dimension quantifies self-similarity and complexity at many scales.\n",
    "    *   **How:** Box-counting or related algorithms.\n",
    "    *   **References:** See, e.g., Fractal dimension of decision boundaries.\n",
    "    *   **Use:** High fractal dimension = very high expressiveness.\n",
    "\n",
    "5.  **Empirical Complexity on Synthetic Data**\n",
    "    *   **What:** Use challenging synthetic benchmarks (moons, spirals, etc.), train your models, and compare the error rate: who can fit the most complicated boundary?\n",
    "    *   **Why:** Not a geometric measure, but a proxy for expressiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8679d4c9",
   "metadata": {},
   "source": [
    "| Method                      | What is Quantified       | Works for ReLU? | Works for KAN? | Relative Difficulty |\n",
    "|-----------------------------|--------------------------|-----------------|----------------|---------------------|\n",
    "| Linear regions              | Piecewise regions        | Yes             | Limited        | Med-hard (exact)    |\n",
    "| Boundary length/surface     | Complexity of boundary  | Yes             | Yes            | Easy                |\n",
    "| Curvature                   | Bendiness                | Yes             | Yes            | Med                 |\n",
    "| Fractal dimension           | Self-similarity          | Yes             | Yes            | Hard                |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c398a30",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m total_length\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Example:\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m bl_mlp \u001b[38;5;241m=\u001b[39m \u001b[43mestimate_boundary_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m bl_kan \u001b[38;5;241m=\u001b[39m estimate_boundary_length(kan, X)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEstimated decision boundary length (MLP): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbl_mlp\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[40], line 15\u001b[0m, in \u001b[0;36mestimate_boundary_length\u001b[0;34m(model, X, resolution)\u001b[0m\n\u001b[1;32m     13\u001b[0m     logits \u001b[38;5;241m=\u001b[39m model(grid_torch)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mreshape(xx\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     14\u001b[0m preds \u001b[38;5;241m=\u001b[39m (logits \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mskimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m measure\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Find contours at class boundary\u001b[39;00m\n\u001b[1;32m     17\u001b[0m contours \u001b[38;5;241m=\u001b[39m measure\u001b[38;5;241m.\u001b[39mfind_contours(preds, \u001b[38;5;241m0.5\u001b[39m)\n",
      "File \u001b[0;32m/net/store/cv/users/luniehaus/dev-uos/miniconda/envs/pykan/lib/python3.9/site-packages/skimage/__init__.py:124\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of the scikit during the build\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 124\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_shared\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m geometry\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m geometry\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32mgeometry.pyx:1\u001b[0m, in \u001b[0;36minit skimage._shared.geometry\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "# Assuming you have trained `model` and have data X, y (see previous code)\n",
    "import numpy as np\n",
    "\n",
    "def estimate_boundary_length(model, X, resolution=400):\n",
    "    # Grid in 2D\n",
    "    x_min, x_max = X[:,0].min()-0.5, X[:,0].max()+0.5\n",
    "    y_min, y_max = X[:,1].min()-0.5, X[:,1].max()+0.5\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, resolution),\n",
    "                         np.linspace(y_min, y_max, resolution))\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "    grid_torch = torch.tensor(grid).float()\n",
    "    with torch.no_grad():\n",
    "        logits = model(grid_torch).cpu().numpy().reshape(xx.shape)\n",
    "    preds = (logits > 0).astype(int)\n",
    "    from skimage import measure\n",
    "    # Find contours at class boundary\n",
    "    contours = measure.find_contours(preds, 0.5)\n",
    "    total_length = 0.0\n",
    "    for contour in contours:\n",
    "        # contour is a N x 2 array of [y, x] points\n",
    "        # Convert to data coordinates\n",
    "        xs = x_min + (x_max - x_min) * contour[:,1]/(resolution-1)\n",
    "        ys = y_min + (y_max - y_min) * contour[:,0]/(resolution-1)\n",
    "        points = np.stack([xs, ys], axis=1)\n",
    "        seg_lens = np.sqrt(np.sum((points[1:] - points[:-1])**2, axis=1))\n",
    "        total_length += seg_lens.sum()\n",
    "    return total_length\n",
    "\n",
    "# Example:\n",
    "bl_mlp = estimate_boundary_length(mlp, X)\n",
    "bl_kan = estimate_boundary_length(kan, X)\n",
    "print(f\"Estimated decision boundary length (MLP): {bl_mlp:.2f}\")\n",
    "print(f\"Estimated decision boundary length (KAN): {bl_kan:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744a6efa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mskimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m measure\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mestimate_boundary_length\u001b[39m(model, X, resolution\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m400\u001b[39m):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Grid in 2D\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     x_min, x_max \u001b[38;5;241m=\u001b[39m X[:,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmin()\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m, X[:,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m0.5\u001b[39m\n",
      "File \u001b[0;32m/net/store/cv/users/luniehaus/dev-uos/miniconda/envs/pykan/lib/python3.9/site-packages/skimage/__init__.py:124\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of the scikit during the build\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 124\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_shared\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m geometry\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m geometry\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32mgeometry.pyx:1\u001b[0m, in \u001b[0;36minit skimage._shared.geometry\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from skimage import measure\n",
    "\n",
    "def estimate_boundary_length(model, X, resolution=400):\n",
    "    # Grid in 2D\n",
    "    x_min, x_max = X[:,0].min()-0.5, X[:,0].max()+0.5\n",
    "    y_min, y_max = X[:,1].min()-0.5, X[:,1].max()+0.5\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, resolution),\n",
    "                         np.linspace(y_min, y_max, resolution))\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "    grid_torch = torch.tensor(grid).float()\n",
    "    with torch.no_grad():\n",
    "        logits = model(grid_torch).cpu().numpy().reshape(xx.shape)\n",
    "    preds = (logits > 0).astype(int)\n",
    "    # Find contours at class boundary\n",
    "    contours = measure.find_contours(preds, 0.5)\n",
    "    total_length = 0.0\n",
    "    for contour in contours:\n",
    "        # contour is a N x 2 array of [y, x] points\n",
    "        # Convert to data coordinates\n",
    "        xs = x_min + (x_max - x_min) * contour[:,1]/(resolution-1)\n",
    "        ys = y_min + (y_max - y_min) * contour[:,0]/(resolution-1)\n",
    "        points = np.stack([xs, ys], axis=1)\n",
    "        seg_lens = np.sqrt(np.sum((points[1:] - points[:-1])**2, axis=1))\n",
    "        total_length += seg_lens.sum()\n",
    "    return total_length\n",
    "\n",
    "# Example:\n",
    "# Assuming mlp and kan are defined and X is your data\n",
    "# bl_mlp = estimate_boundary_length(mlp, X)\n",
    "# bl_kan = estimate_boundary_length(kan, X)\n",
    "# print(f\"Estimated decision boundary length (MLP): {bl_mlp:.2f}\")\n",
    "# print(f\"Estimated decision boundary length (KAN): {bl_kan:.2f}\")\n",
    "\n",
    "# To resolve the ModuleNotFoundError:\n",
    "# You need to install the scikit-image library.\n",
    "# You can do this using pip:\n",
    "# pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d42da4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mskimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m measure\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mestimate_boundary_length\u001b[39m(model, X, resolution\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m400\u001b[39m):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Grid in 2D\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     x_min, x_max \u001b[38;5;241m=\u001b[39m X[:,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmin()\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m, X[:,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m0.5\u001b[39m\n",
      "File \u001b[0;32m/net/store/cv/users/luniehaus/dev-uos/miniconda/envs/pykan/lib/python3.9/site-packages/skimage/__init__.py:124\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of the scikit during the build\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 124\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_shared\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m geometry\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m geometry\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32mgeometry.pyx:1\u001b[0m, in \u001b[0;36minit skimage._shared.geometry\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from skimage import measure\n",
    "\n",
    "def estimate_boundary_length(model, X, resolution=400):\n",
    "    # Grid in 2D\n",
    "    x_min, x_max = X[:,0].min()-0.5, X[:,0].max()+0.5\n",
    "    y_min, y_max = X[:,1].min()-0.5, X[:,1].max()+0.5\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, resolution),\n",
    "                         np.linspace(y_min, y_max, resolution))\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "    grid_torch = torch.tensor(grid).float()\n",
    "    with torch.no_grad():\n",
    "        logits = model(grid_torch).cpu().numpy().reshape(xx.shape)\n",
    "    preds = (logits > 0).astype(int)\n",
    "    # Find contours at class boundary\n",
    "    contours = measure.find_contours(preds, 0.5)\n",
    "    total_length = 0.0\n",
    "    for contour in contours:\n",
    "        # contour is a N x 2 array of [y, x] points\n",
    "        # Convert to data coordinates\n",
    "        xs = x_min + (x_max - x_min) * contour[:,1]/(resolution-1)\n",
    "        ys = y_min + (y_max - y_min) * contour[:,0]/(resolution-1)\n",
    "        points = np.stack([xs, ys], axis=1)\n",
    "        seg_lens = np.sqrt(np.sum((points[1:] - points[:-1])**2, axis=1))\n",
    "        total_length += seg_lens.sum()\n",
    "    return total_length\n",
    "\n",
    "# Example:\n",
    "# Assuming mlp and kan are defined and X is your data\n",
    "# bl_mlp = estimate_boundary_length(mlp, X)\n",
    "# bl_kan = estimate_boundary_length(kan, X)\n",
    "# print(f\"Estimated decision boundary length (MLP): {bl_mlp:.2f}\")\n",
    "# print(f\"Estimated decision boundary length (KAN): {bl_kan:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e444fbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def estimate_boundary_length(model, X, resolution=400):\n",
    "    try:\n",
    "        from skimage import measure\n",
    "    except ImportError:\n",
    "        print(\"Error: scikit-image is not installed. Please install it using 'pip install scikit-image'\")\n",
    "        return None  # Or raise the exception if you want to stop execution\n",
    "\n",
    "    # Grid in 2D\n",
    "    x_min, x_max = X[:,0].min()-0.5, X[:,0].max()+0.5\n",
    "    y_min, y_max = X[:,1].min()-0.5, X[:,1].max()+0.5\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, resolution),\n",
    "                         np.linspace(y_min, y_max, resolution))\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "    grid_torch = torch.tensor(grid).float()\n",
    "    with torch.no_grad():\n",
    "        logits = model(grid_torch).cpu().numpy().reshape(xx.shape)\n",
    "    preds = (logits > 0).astype(int)\n",
    "\n",
    "    # Find contours at class boundary\n",
    "    contours = measure.find_contours(preds, 0.5)\n",
    "    total_length = 0.0\n",
    "    for contour in contours:\n",
    "        # contour is a N x 2 array of [y, x] points\n",
    "        # Convert to data coordinates\n",
    "        xs = x_min + (x_max - x_min) * contour[:,1]/(resolution-1)\n",
    "        ys = y_min + (y_max - y_min) * contour[:,0]/(resolution-1)\n",
    "        points = np.stack([xs, ys], axis=1)\n",
    "        seg_lens = np.sqrt(np.sum((points[1:] - points[:-1])**2, axis=1))\n",
    "        total_length += seg_lens.sum()\n",
    "    return total_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27449f1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Example:\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m bl_mlp \u001b[38;5;241m=\u001b[39m \u001b[43mestimate_boundary_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m bl_kan \u001b[38;5;241m=\u001b[39m estimate_boundary_length(kan, X)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEstimated decision boundary length (MLP): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbl_mlp\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[38], line 6\u001b[0m, in \u001b[0;36mestimate_boundary_length\u001b[0;34m(model, X, resolution)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mestimate_boundary_length\u001b[39m(model, X, resolution\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m400\u001b[39m):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 6\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mskimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m measure\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: scikit-image is not installed. Please install it using \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install scikit-image\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/net/store/cv/users/luniehaus/dev-uos/miniconda/envs/pykan/lib/python3.9/site-packages/skimage/__init__.py:124\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of the scikit during the build\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 124\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_shared\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m geometry\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m geometry\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32mgeometry.pyx:1\u001b[0m, in \u001b[0;36minit skimage._shared.geometry\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "# Example:\n",
    "bl_mlp = estimate_boundary_length(mlp, X)\n",
    "bl_kan = estimate_boundary_length(kan, X)\n",
    "print(f\"Estimated decision boundary length (MLP): {bl_mlp:.2f}\")\n",
    "print(f\"Estimated decision boundary length (KAN): {bl_kan:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66685a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pykan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
